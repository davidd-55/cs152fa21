{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccc9fbd3",
   "metadata": {},
   "source": [
    "# Plan\n",
    "\n",
    "1. Read through code (~5 minutes)\n",
    "2. Get into groups and discuss code (~2 minutes)\n",
    "3. Ask questions on the sheet (~5 minutes)\n",
    "4. Work on \"Questions to answer\" (~10 minutes)\n",
    "5. Work on \"Things to explore\" (~10 minutes)\n",
    "6. Work on the \"Challenge\" (~20 minutes)\n",
    "7. Work on \"What's next?\"\n",
    "\n",
    "Getting started:\n",
    "\n",
    "- I recommend cloning this repository (or pulling changes if you already have it cloned)\n",
    "- Starting jupyter\n",
    "- Then duplicating this file so that you can alter it without confusing `git`\n",
    "\n",
    "Some tools to use:\n",
    "\n",
    "- You can create a cell above the current cell by typing \"esc\" then \"a\"\n",
    "- You can create a cell below the current cell by typing \"esc\" then \"b\"\n",
    "- You should copy code into newly created cells, alter it, print out the results, etc.\n",
    "- You can do this for single lines or you can copy, for example, the `for batch, (X, Y) in enumerate(dataloader):` loop out of `train_one_epoch` and make minor changes so that it works outside of the function\n",
    "- I will frequently put a break a the end of the for-loop so that it only iterates one time (so that I don't have to wait for every iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4977eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2eb52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def stopwatch(label: str):\n",
    "    start = timer()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        print(f\"{label}: {timer() - start:6.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "514c3c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_data_loaders(path, batch_size, valid_batch_size):\n",
    "\n",
    "    # MNIST specific transforms\n",
    "    mnist_xforms = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    # Training data loader\n",
    "    train_dataset = MNIST(root=path, train=True, download=True, transform=mnist_xforms)\n",
    "\n",
    "    tbs = len(train_dataset) if batch_size == 0 else batch_size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=tbs, shuffle=True)\n",
    "\n",
    "    # Validation data loader\n",
    "    valid_dataset = MNIST(root=path, train=False, download=True, transform=mnist_xforms)\n",
    "\n",
    "    vbs = len(valid_dataset) if valid_batch_size == 0 else valid_batch_size\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=vbs, shuffle=True)\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdfcb854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        first_layer = nn.Flatten()\n",
    "        middle_layers = [\n",
    "            nn.Sequential(nn.Linear(nlminus1, nl), nn.ReLU())\n",
    "            for nl, nlminus1 in zip(layer_sizes[1:-1], layer_sizes)\n",
    "        ]\n",
    "        last_layer = nn.Linear(layer_sizes[-2], layer_sizes[-1])\n",
    "\n",
    "        all_layers = [first_layer] + middle_layers + [last_layer]\n",
    "\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.layers(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "698b2917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloader, model, loss_fn, optimizer, device):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    num_batches = len(train_loader)\n",
    "    batches_to_print = [0, num_batches // 3, 2 * num_batches // 3, num_batches - 1]\n",
    "\n",
    "    for batch, (X, Y) in enumerate(dataloader):\n",
    "\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "        output = model(X)\n",
    "\n",
    "        loss = loss_fn(output, Y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch in batches_to_print:\n",
    "            print(f\"Batch {batch+1:>5} of {num_batches}: loss={loss.item():>6.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26dea3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_validation_accuracy(dataloader, model, loss_fn, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    N = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    valid_loss, num_correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for X, Y in dataloader:\n",
    "\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            output = model(X)\n",
    "\n",
    "            valid_loss += loss_fn(output, Y).item()\n",
    "            num_correct += (output.argmax(1) == Y).type(torch.float).sum().item()\n",
    "\n",
    "        valid_loss /= num_batches\n",
    "        valid_accuracy = num_correct / N\n",
    "\n",
    "    print(f\"Validation accuracy : {(100*valid_accuracy):>6.3f}%\")\n",
    "    print(f\"Validation loss     : {valid_loss:>6.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e32ddf6",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab40d2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 'cuda' device.\n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters\n",
    "data_path = \"../data\"\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 1024\n",
    "valid_batch_size = 0\n",
    "learning_rate = 1e-2\n",
    "num_epochs = 2\n",
    "\n",
    "# Training device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using '{device}' device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d16852",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e485982c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mambaforge/envs/cs152/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /tmp/pip-req-build-pma2oi4d/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Get data loaders\n",
    "train_loader, valid_loader = get_mnist_data_loaders(\n",
    "    data_path, batch_size, valid_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af956265",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd211ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=50, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (3): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create neural network model\n",
    "nx = train_loader.dataset.data.shape[1:].numel()\n",
    "ny = len(train_loader.dataset.classes)\n",
    "layer_sizes = (nx, 512, 50, ny)\n",
    "\n",
    "model = NeuralNetwork(layer_sizes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bd70e2",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c754be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training utilities\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad9a729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Batch     1 of 59: loss= 2.306\n",
      "Batch    20 of 59: loss= 2.243\n",
      "Batch    40 of 59: loss= 2.154\n",
      "Batch    59 of 59: loss= 2.062\n",
      "Epoch time          : 11.685s\n",
      "Validation accuracy : 56.680%\n",
      "Validation loss     :  2.047\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Batch     1 of 59: loss= 2.053\n",
      "Batch    20 of 59: loss= 1.912\n",
      "Batch    40 of 59: loss= 1.780\n",
      "Batch    59 of 59: loss= 1.609\n",
      "Epoch time          : 11.232s\n",
      "Validation accuracy : 64.820%\n",
      "Validation loss     :  1.610\n",
      "\n",
      "Done! Total time for 2 epochs: 26.706s\n"
     ]
    }
   ],
   "source": [
    "with stopwatch(f\"\\nDone! Total time for {num_epochs} epochs\"):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}\\n-------------------------------\")\n",
    "        with stopwatch(\"Epoch time          \"):\n",
    "            train_one_epoch(train_loader, model, loss_fn, optimizer, device)\n",
    "        compute_validation_accuracy(valid_loader, model, loss_fn, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa45cb4",
   "metadata": {},
   "source": [
    "# Questions to answer\n",
    "\n",
    "(Try to answer these in your group prior to running or altering any code.)\n",
    "\n",
    "- What is the shape of `output` in the function `train_one_epoch`?\n",
    "- What values would you expect to see in `output`?\n",
    "- What is the shape of `Y` in the function `train_one_epoch`?\n",
    "- Describe each part of `(output.argmax(1) == Y).type(torch.float).sum().item()`\n",
    "- What happens when you rerun the training cell for additional epoch (without rerunning any other cells)?\n",
    "- What happens to if force device to be `\"cpu\"`?\n",
    "- How could you make this code run \"stochastic gradient descent\"?\n",
    "- How could you make this code run \"batch gradient descent\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfe974d",
   "metadata": {},
   "source": [
    "# Things to explore\n",
    "\n",
    "- change the hidden layer activation functions to sigmoid\n",
    "- change the hidden layer activation functions to [something else](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n",
    "- change the optimizer from `SGD` to `Adam` and try to train the network again\n",
    "\n",
    "You can also try these if you feel like you have plenty of time. You can also choose to come back to them after working on the Challenge below\n",
    "\n",
    "- (optional) try adding a [dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout) layer somewhere in your network\n",
    "- (optional) try switching the dataset to either [KMNIST](https://pytorch.org/vision/0.8/datasets.html#kmnist) or [FashionMNIST](https://pytorch.org/vision/0.8/datasets.html#fashion-mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896ebcb4",
   "metadata": {},
   "source": [
    "# Challenge\n",
    "\n",
    "Train a model and get the highest accuracy possible by adjusting hyperparameters and the model architecture (i.e., the number of layers, the number of neurons per layer, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aacc889",
   "metadata": {},
   "source": [
    "# What's next?\n",
    "\n",
    "Move the inference cells below to a new file, and then try to make them work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c597bb5",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7263e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = \"l14-model.pth\"\n",
    "torch.save(model.state_dict(), model_filename)\n",
    "print(\"Saved PyTorch Model State to\", model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c525d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(layer_sizes)\n",
    "model.load_state_dict(torch.load(model_filename))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Index of example\n",
    "i = 0\n",
    "\n",
    "# Example input and output\n",
    "x, y = valid_loader.dataset[i][0], valid_loader.dataset[i][1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(x)\n",
    "    prediction = output[0].argmax(0)\n",
    "    print(f\"Prediction : {prediction}\")\n",
    "    print(f\"Target     : {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537417e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
