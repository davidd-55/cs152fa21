{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1c7670f",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8744658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82b0723",
   "metadata": {},
   "source": [
    "## Create fake input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef6e76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of training examples\n",
    "N = 100\n",
    "\n",
    "# Number of inputs and outputs (based on diagram)\n",
    "nx = 3\n",
    "ny = 2\n",
    "\n",
    "# Random inputs and outputs (just for sake of computation)\n",
    "X = torch.randn(N, nx)\n",
    "Y = torch.randn(N, ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42456bc9",
   "metadata": {},
   "source": [
    "## Create a simple model based on the diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0fa686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1 / (1 + torch.exp(-Z))\n",
    "\n",
    "\n",
    "# Number of layers and neurons per layer (based on diagram)\n",
    "# Our class convention is to refer the input as layer \"0\"\n",
    "neurons_per_layer = (nx, 3, 2, ny)\n",
    "num_layers = len(neurons_per_layer) - 1\n",
    "\n",
    "# Layer parameters (W and b)\n",
    "Ws = {}\n",
    "bs = {}\n",
    "\n",
    "# Layers 1, 2, ..., L\n",
    "for layer in range(1, num_layers + 1):\n",
    "    nl = neurons_per_layer[layer]\n",
    "    prev_nl = neurons_per_layer[layer - 1]\n",
    "\n",
    "    Ws[layer] = torch.randn(nl, prev_nl)\n",
    "    bs[layer] = torch.randn(nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd106642",
   "metadata": {},
   "source": [
    "## Compute model output (forward propagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f95c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3]) @ torch.Size([3, 3]) + torch.Size([3]) = torch.Size([100, 3])\n",
      "torch.Size([100, 3]) @ torch.Size([3, 2]) + torch.Size([2]) = torch.Size([100, 2])\n",
      "torch.Size([100, 2]) @ torch.Size([2, 2]) + torch.Size([2]) = torch.Size([100, 2])\n",
      "Output shape (N, ny): torch.Size([100, 2])\n"
     ]
    }
   ],
   "source": [
    "# Forward propagation (we need to save A matrices to compute gradients later)\n",
    "As = [X]\n",
    "for W, b in zip(Ws.values(), bs.values()):\n",
    "    Z = As[-1] @ W.T + b\n",
    "    print(f\"{As[-1].shape} @ {W.T.shape} + {b.shape} = {Z.shape}\")\n",
    "    As.append(sigmoid(Z))\n",
    "\n",
    "Yhat = As[-1]\n",
    "\n",
    "print(\"Output shape (N, ny):\", Yhat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc7d473",
   "metadata": {},
   "source": [
    "## Backpropagation from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a03c6911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3538485765457153\n"
     ]
    }
   ],
   "source": [
    "# Compute loss as the mean-square-error\n",
    "mse_loss = torch.mean((Yhat - Y) ** 2)\n",
    "print(\"Loss:\", mse_loss.item())\n",
    "\n",
    "# Compute gradients for W^[3] and b^[3]\n",
    "dL_dY = Yhat - Y\n",
    "dY_dZ3 = Yhat * (1 - Yhat)\n",
    "\n",
    "dZ3 = dL_dY * dY_dZ3\n",
    "\n",
    "dW3 = (1 / N) * dZ3.T @ As[2]\n",
    "db3 = dZ3.mean(dim=0)\n",
    "\n",
    "# Compute gradients for W^[2] and b^[2]\n",
    "dZ2 = dZ3 @ Ws[3] * ((As[2] * (1 - As[2])))\n",
    "\n",
    "dW2 = (1 / N) * dZ2.T @ As[1]\n",
    "db2 = dZ2.mean(dim=0)\n",
    "\n",
    "# Compute gradients for W^[1] and b^[1]\n",
    "dZ1 = dZ2 @ Ws[2] * ((As[1] * (1 - As[1])))\n",
    "\n",
    "dW1 = (1 / N) * dZ1.T @ X\n",
    "db1 = dZ1.mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdcc15e",
   "metadata": {},
   "source": [
    "## Backpropagation using a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff9f386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dWs = {}\n",
    "dbs = {}\n",
    "\n",
    "# Compute dZ for last layer\n",
    "dL_dY = Yhat - Y\n",
    "dY_dZ3 = Yhat * (1 - Yhat)\n",
    "\n",
    "dZ = dL_dY * dY_dZ3\n",
    "\n",
    "# Start at the last layer and move to the first\n",
    "for layer in range(num_layers, 0, -1):\n",
    "    dWs[layer] = (1 / N) * dZ.T @ As[layer - 1]\n",
    "    dbs[layer] = dZ.mean(dim=0)\n",
    "\n",
    "    if layer != 1:\n",
    "        dZ = dZ @ Ws[layer] * ((As[layer - 1] * (1 - As[layer - 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc82dbc",
   "metadata": {},
   "source": [
    "## Forward and backward propagation using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48303e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3538485765457153\n"
     ]
    }
   ],
   "source": [
    "# Let's copy the Ws and bs from above, but set them\n",
    "# up for auto-differentiation\n",
    "WsAuto = {}\n",
    "bsAuto = {}\n",
    "for layer in range(1, num_layers + 1):\n",
    "    WsAuto[layer] = Ws[layer].clone().detach().requires_grad_(True)\n",
    "    bsAuto[layer] = bs[layer].clone().detach().requires_grad_(True)\n",
    "\n",
    "# Forward propagation (same as above, but using PyTorch functionality)\n",
    "prev_A = X\n",
    "for W, b in zip(WsAuto.values(), bsAuto.values()):\n",
    "    Z = torch.nn.functional.linear(prev_A, W, b)\n",
    "    prev_A = torch.sigmoid(Z)\n",
    "Yhat = prev_A\n",
    "\n",
    "# Compute loss (same as above)\n",
    "mse_loss = torch.mean((Yhat - Y) ** 2)\n",
    "print(\"Loss:\", mse_loss.item())\n",
    "\n",
    "# Automatically compute derivatives\n",
    "mse_loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf2d38c",
   "metadata": {},
   "source": [
    "## Compare computed gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ae248e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We shouldn't compare floating-point numbers using \"==\" since results\n",
    "#  can differ based on the order of operations.\n",
    "assert torch.allclose(dW3, WsAuto[3].grad)\n",
    "assert torch.allclose(db3, bsAuto[3].grad)\n",
    "\n",
    "assert torch.allclose(dW2, WsAuto[2].grad)\n",
    "assert torch.allclose(db2, bsAuto[2].grad)\n",
    "\n",
    "assert torch.allclose(dW1, WsAuto[1].grad)\n",
    "assert torch.allclose(db1, bsAuto[1].grad)\n",
    "\n",
    "for layer in range(1, num_layers + 1):\n",
    "    assert torch.allclose(WsAuto[layer].grad, dWs[layer])\n",
    "    assert torch.allclose(bsAuto[layer].grad, dbs[layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20256917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
